---
title: "P8106 Homework1"
author: "Yuki Joyama"
date: "2024-02-10"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message=FALSE,
  warning=FALSE
  )
```

```{r}
# load libraries
library(tidyverse)
library(caret)
library(tidymodels)
library(plotmo)
library(kknn)
library(FNN) 
library(pls)

# read csv files 
df_test = read_csv("./data/housing_test.csv") |> 
  janitor::clean_names()
  
df_train = read_csv("./data/housing_training.csv") |> 
  janitor::clean_names()

```

## (a) Lasso model on the training data
I will use caret to fit a lasso model. 

```{r}
# set up 10-fold CV
ctrl1 <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 5,
  selectionFunction = "best"
)

set.seed(1)

# find lambda by CV
lasso.fit <- 
  train(
    sale_price ~ .,
    data = df_train,
    method = "glmnet",
    tuneGrid = expand.grid(
      alpha = 1,
      lambda = exp(seq(10, 0, length = 100))
    ),
    trControl = ctrl1
  )

# plot RMSE and lambda
plot(lasso.fit, xTrans = log)

# print the best tuning parameter
lasso.fit$bestTune

# Obtain the test error
lasso.pred <- predict(lasso.fit, newdata = df_test)
mean((lasso.pred - pull(df_test, "sale_price"))^2) # test error
```

The selected tuning parameter is $\lambda=$ 62.89 ($\alpha=$ 1)  
The test error is 440215066  

Now, I will apply 1SE rule to obtain the most regularized model. 

```{r}
# apply 1SE rule 
ctrl2 <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 5,
  selectionFunction = "oneSE"
)

set.seed(1)

lasso.fit_oneSE <- 
  train(
    sale_price ~ .,
    data = df_train,
    method = "glmnet",
    tuneGrid = expand.grid(
      alpha = 1,
      lambda = exp(seq(10, 0, length = 100))
    ),
    trControl = ctrl2
  )

# coefficients in the final model
coef(lasso.fit_oneSE$finalModel, s = lasso.fit_oneSE$bestTune$lambda)

# Obtain the test error
lasso.pred_oneSE <- predict(lasso.fit_oneSE, newdata = df_test)
mean((lasso.pred_oneSE - pull(df_test, "sale_price"))^2) # test error
```

36 predictors are included in the model. 

## (b) Elastic net model on the training data
```{r}
# fit the model 
set.seed(1)

enet.fit <- 
  train(
    sale_price ~ .,
    data = df_train,
    method = "glmnet",
    tuneGrid = expand.grid(
      alpha = seq(0, 1, length = 20),
      lambda = exp(seq(10, 0, length = 100))
    ),
    trControl = ctrl1
  )

# check the best tuning parameter
enet.fit$bestTune

# plot RMSE, lambda and alpha
myCol <- rainbow(25)
myPar <- list(
  superpose.symbol = list(col = myCol),
  superpose.line = list(col = myCol)
)

plot(enet.fit, par.settings = myPar, xTrans = log)

# coefficients in the final model
coef(enet.fit$finalModel, s = enet.fit$bestTune$lambda)

# obtain predicted values
enet.pred <- predict(enet.fit, newdata = df_test)

# test error
mean((enet.pred - pull(df_test, "sale_price"))^2)
```

The selected tuning parameters are $\lambda=$ 580.35 and $\alpha=$ 0.0526 
The test error is 438502352  

1SE rule can be applied in $\lambda$s for each $\alpha$. 

```{r}
# apply 1SE rule 
set.seed(1)

enet.fit_oneSE <- 
  train(
    sale_price ~ .,
    data = df_train,
    method = "glmnet",
    tuneGrid = expand.grid(
      alpha = seq(0, 1, length = 20),                                    
      lambda = exp(seq(10, 0, length = 100))
    ),
    trControl = ctrl2
  )

# check the tuning parameters
enet.fit_oneSE$bestTune

# Obtain the test error
enet.pred_oneSE <- predict(enet.fit_oneSE, newdata = df_test)
mean((enet.pred_oneSE - pull(df_test, "sale_price"))^2) # test error
```

Now, the optimal tuning parameters are $\lambda=$ 5924.60 and $\alpha=$ 0 

## (c) Partial least squares model on the training data
```{r}
# using caret

# prepare x and y
# training 
x <- model.matrix(sale_price ~ ., df_train)[, -1]
y <- df_train$sale_price

# test
x2 <- model.matrix(sale_price ~ ., df_test)[, -1]
y2 <- df_test$sale_price

# fit a partial least squares model on the training data
set.seed(2)

pls.fit <- train(
  x, y,
  method = "pls",
  tuneGrid = data.frame(ncomp = 8:38),
  trControl = ctrl1,
  preProcess = c("center", "scale")
)

summary(pls.fit)

# obtain predicted values 
pred.pls <- predict(
  pls.fit, 
  newdata = x2
)

# visualize RMSE and the number of components
ggplot(pls.fit, highlight = T) + theme_bw()

# test MSE
mean((pred.pls - y2)^2)
```

11 components are included in the partial least squares model on the training data.   
The test error is 451276530

## (d) The best model for response prediction
```{r}
# compare models

# resampling 
resamp <- resamples(list(
  lasso = lasso.fit,
  lasso_oneSE = lasso.fit_oneSE,
  elastic_net = enet.fit,
  elastic_net_oneSE = enet.fit_oneSE,
  pls = pls.fit
))

summary(resamp)

# visualize RMSEs 
bwplot(resamp, metric = "RMSE")
```

I choose the partial least square model as the best model in this practice because it has the smallest mean of RMSE among five models. 

## (e) Alternative meta-engine 
I used caret in (b), so I will retrain the model with tidymodels.

```{r}
# set up cv (10 fold)
set.seed(2)
cv_folds <- vfold_cv(df_train, v = 10)

# using tidymodels
enet_spec <- linear_reg(penalty = tune(), mixture = tune()) |> 
  set_engine("glmnet") |> 
  set_mode("regression")

# set the grid for lambda and alpha
enet_grid_set <- parameters(
  penalty(range = c(0, 10), trans = log_trans()), # lambda exp(0)-exp(10)
  mixture(range = c(0, 1)) # alpha 0 - 1
)

# set levels for lambda and alpha
enet_grid <- grid_regular(enet_grid_set, levels = c(100, 20))

enet_workflow <- workflow() |> 
  add_model(enet_spec) |> 
  add_formula(sale_price ~ .)

# use cv to fit the elastic net model
enet_tune <- tune_grid(
  enet_workflow,
  resamples = cv_folds,
  grid = enet_grid
)

# visualize RMSE and tuning parameters
autoplot(enet_tune, metric = "rmse") +
  theme(legend.position = "top") +
  labs(color = "Mixing Percentage \n (Alpha Values)")

# select the best tuning parameters
enet_best <- select_best(enet_tune, metric = "rmse")
enet_best

# final model
final_enet_spec <- enet_spec |> 
  update(penalty = enet_best$penalty, mixture = enet_best$mixture)

enet_fit <- fit(final_enet_spec, formula = sale_price ~ ., data = df_train)

# get coefficients
enet_model <- extract_fit_engine(enet_fit)
coef(enet_model, s = enet_best$penalty)

# obtain test RMSE
enet.pred_tidy <- predict(enet_fit, new_data = df_test)
# RMSE
sqrt(mean((enet.pred_tidy[[1]] - pull(df_test, "sale_price"))^2))
```

The selected tuning parameters in this model are $\lambda=$ 642.04 and $\alpha=$ 0.0526  

Although the $\alpha$ is the same, the selected $\lambda$ is different 580.35 in caret. This may be due to the different calclation methods used in each package.




